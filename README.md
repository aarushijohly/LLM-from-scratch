Implemented a GPT model from scratch to generate text, pre-trained on unlabeled data, and fine-tuned for classification and following instructions.
USed: Python, PyTorch

Components coded includes: Tokenization, Attention mechanism(Causal attention and multi-head attention).
