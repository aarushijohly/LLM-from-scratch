{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae36585-1e26-4967-9e29-2d9ed29c22b4",
   "metadata": {},
   "source": [
    "# Creating token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19bcdcd-a899-4ed2-bb52-45218cee9f3d",
   "metadata": {},
   "source": [
    "Illustration of how the token ID to embedding vector conversion works with a hands on example.\n",
    "\n",
    "Suppose we have the following four tokens with IDs 2, 3, 5 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df6c13a-833a-4e5b-9079-beb304806d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids=torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49075137-a0c5-4b3f-a789-43c381c51c53",
   "metadata": {},
   "source": [
    "For the sake of simplicity we are going to use a small vocabulary of 6 words(instead of 50,257 words in the BPE tokenizer vocabulary), and we want to create embeddings of size 3(in GPT-3 the embedding size is 12,288 dimentions).\n",
    "\n",
    "\n",
    "vocab: Each of these 6 words will be mapped in R3\n",
    "\n",
    "quick-->4\n",
    "\n",
    "fox-->0\n",
    "\n",
    "is-->3\n",
    "\n",
    "in-->2\n",
    "\n",
    "the-->5\n",
    "\n",
    "house-->1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0a4a8-38a8-43de-b660-edcc13df41f1",
   "metadata": {},
   "source": [
    "torch.nn.Embedding return a simple lookup table that stores embeddings of a fixed dictionary and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cac87a2-ea10-49e4-90e5-53314b8d2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=6\n",
    "output_dim=3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim) #creates a dictionary\n",
    "#this initialize the weights of the embedding matrix in a random manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae3722f-bc67-471b-8aa1-a31d2b8830ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)\n",
    "#these are the initial weights which needs to be optimized during LLM training as part of the LLM optmization itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b73477-c09c-475a-88ee-ec9e403b8874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098b5b95-c7d6-458b-afff-a20babca5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))\n",
    "\n",
    "# a look up operation that retrieves rows from the embedding layer weight matrix using a token ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2665d81-fb92-4800-8c96-380afb0f1fdb",
   "metadata": {},
   "source": [
    "Positional embeddings (Encoding word positions):\n",
    "\n",
    "We encode the input tokens into 256-dimensional vector representation.\n",
    "\n",
    "Assumption: The token IDs were created by the BPE tokenizer which has a vocabulary size of 50,257."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6740bb24-1701-4755-b582-b1c62fde9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=50257\n",
    "optput_dim=256\n",
    "token_embedding_layes=torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c316d-1e35-4451-8880-e9312e8179f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eff723-7f6c-4055-b8d9-7cbf7fc2a3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe09bc7-f3b8-4731-a848-acd0fe608610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77b307-791c-4058-9582-efc040284b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56c072-8ec8-42d0-a522-9a83282473a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
